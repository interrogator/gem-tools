{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological operations and Non-Maximum Suppression (NMS) for document element detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For computer vision\n",
    "import cv2\n",
    "\n",
    "# For logging\n",
    "from logging import FileHandler\n",
    "from vlogging import VisualRecord\n",
    "import logging\n",
    "\n",
    "# For connected-component analysis\n",
    "from skimage.filters import threshold_adaptive\n",
    "from skimage import measure\n",
    "\n",
    "# For connected-component analysis and Non-Maximum Suppression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the logging file and set the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"detect_elements\")\n",
    "fh = FileHandler(\"detect_elements_log.html\", mode = \"w\")\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# Prevent logger output in IPython\n",
    "logger.propagate = False\n",
    "\n",
    "# Define a function to handle visual logging\n",
    "def vlog(image, title):\n",
    "    logger.debug(VisualRecord(title, image, fmt = \"png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement fast Non-Maximum Suppression from PyImageSearch.\n",
    "\n",
    "http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def non_maximum_suppression(boxes, overlapThresh):\n",
    "    # Return an empty list if there are no boxes.\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    # If the bounding boxes are integers, convert them to floats: floats are needed for divisions.\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "        \n",
    "    # Initialize a list of picked indexes.\n",
    "    pick = []\n",
    "    \n",
    "    # Grab the coordinates of the bounding boxes.\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    \n",
    "    # Compute the area of the bounding boxes and sort them by the bottom-right y-coordinate.\n",
    "    area = (x2 - x1 +1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    \n",
    "    # Keep looping while some indexes remain in the list of indexes\n",
    "    while len(idxs) > 0:\n",
    "        # Grab the last index in the list and add the index value to the list of picked indexes\n",
    "        last = len(idxs) -1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        \n",
    "        # Find the largest (x, y) coordinates for the start of the bounding box and the smallest (x, y) coordinates for the end of the bounding box.\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]]) \n",
    "        \n",
    "        # Compute the width and height of the bounding box.\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)  \n",
    "        \n",
    "        # Compute the ratio of overlap.\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        \n",
    "        # Delete all indexes from the index list that overlap the overlap threshold.\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "        \n",
    "    # Return the picked bounding boxes as integers.\n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare the document image.\n",
    "\n",
    "TO DO BEFORE TESTING:\n",
    "\n",
    "1. Set up an argument parser\n",
    "2. Grab the images from a directory\n",
    "3. Write the results on disk\n",
    "4. Loop over the results and prompt for the number of false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('test_images/1967_hft_side_b_lowres_w1200.jpg')\n",
    "\n",
    "# Logging\n",
    "logger.debug(\"Image width: {}, height: {}\".format(image.shape[1], image.shape[0]))\n",
    "vlog(image, \"Original image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "vlog(gray, \"Grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply bilateral filtering to remove detail but preserve edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = (11, 41, 21)\n",
    "blurred = cv2.bilateralFilter(gray, params[0], params[1], params[2])\n",
    "\n",
    "# Logging\n",
    "logger.debug(\"Parameters for bilateral filtering: diameter of the pixel neighbourhood: {}, standard deviation for color: {}, standard deviation for space: {}\".format(params[0], params[1], params[2]))\n",
    "vlog(blurred, \"Bilaterally filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a kernel size for morphological operations.\n",
    "\n",
    "> The kernel size must be determined after deciding input image resolution. It should be based on type size and correspond roughly to the x-height of the font face used for body text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernelsize = (5, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Otsu's thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(T, thresholded) = cv2.threshold(blurred, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "# Logging\n",
    "logger.debug(\"Otsu's threshold: {}\".format(T))\n",
    "vlog(thresholded, \"Thresholded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform morphological operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernelsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphological gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(thresholded.copy(), cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "# Logging\n",
    "logger.debug(\"Kernel size: {}\".format(kernelsize))\n",
    "vlog(gradient, \"Morphological gradient applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eroded = cv2.erode(gradient, None, iterations = 1)\n",
    "\n",
    "# Logging\n",
    "vlog(eroded, \"Morphological gradient eroded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform connected-components labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform connected component labeling and set up a mask for the labels to be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = measure.label(eroded, neighbors = 8, background = 0)\n",
    "\n",
    "gradient_mask = np.zeros(gradient.shape, dtype = \"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the labels twice:\n",
    "    1. Calculate the average number of pixels per label.\n",
    "    2. Decide which labels to include in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First loop\n",
    "\n",
    "numpixels_all = []\n",
    "\n",
    "for (i, label) in enumerate(np.unique(labels)):\n",
    "    if label == -1:\n",
    "        continue\n",
    "    labelmask = np.zeros(gradient.shape, dtype = \"uint8\")\n",
    "    labelmask[labels == label] = 255\n",
    "    numpixels = cv2.countNonZero(labelmask)\n",
    "    numpixels_all.append(numpixels)\n",
    "\n",
    "average = sum(numpixels_all) / len(numpixels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second loop\n",
    "\n",
    "for (i, label) in enumerate(np.unique(labels)):\n",
    "    if label == -1:\n",
    "        continue\n",
    "    labelmask = np.zeros(gradient.shape, dtype = \"uint8\")\n",
    "    labelmask[labels == label] = 255\n",
    "    numpixels = cv2.countNonZero(labelmask)\n",
    "    \n",
    "    if numpixels > (int(average) * 0.05):\n",
    "        gradient_mask = cv2.add(gradient_mask, labelmask)\n",
    "        \n",
    "# Logging\n",
    "logger.debug(\"Average size for label: {}\".format(average))   \n",
    "vlog(gradient_mask, \"Mask for morphological gradient after connected-components labeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Find contours in the processed image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find contours in the image after applying morphological gradient and performing connected-components labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(contours, hierarchy) = cv2.findContours(gradient_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up another mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contour_mask = np.zeros(gradient_mask.shape, dtype = \"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw contours on the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in contours:\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    cv2.rectangle(contour_mask, (x, y), (x + w, y + h), (255, 255, 255), -1)\n",
    "\n",
    "# Logging\n",
    "vlog(contour_mask, \"Contour mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect contours in the mask and draw them on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(maskcontours, maskhierarchy) = cv2.findContours(contour_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original = image.copy()\n",
    "\n",
    "for mc in maskcontours:\n",
    "    (x, y, w, h) = cv2.boundingRect(mc)\n",
    "    cv2.rectangle(original, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "    \n",
    "vlog(original, \"RESULT 1: Contours detected in the contour mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clone = image.copy()\n",
    "\n",
    "for c, h in zip(contours, hierarchy[0]):\n",
    "    area = cv2.contourArea(c)\n",
    "    if h[:][3] == -1 and area >= 25: # Is the hierarchy still needed?\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(clone, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "        \n",
    "vlog(clone, \"RESULT 2: Contours detected in the original image (morphological gradient + connected-components labeling)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply Non-Maximum Suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the contours to get the bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bounding_boxes = []\n",
    "\n",
    "for c in contours:\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    bbox = (x, y, x + w, y + h) # NMS requires a bounding box, not just coordinates!\n",
    "    bounding_boxes.append(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Non-Maximum Suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bounding_boxes_nms = non_maximum_suppression(np.asarray(bounding_boxes), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the remaining contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nms = image.copy()\n",
    "\n",
    "for (startx, starty, endx, endy) in bounding_boxes_nms:\n",
    "    cv2.rectangle(nms, (startx, starty), (endx, endy), (0, 0, 255), 1)\n",
    "    \n",
    "vlog(nms, \"RESULT 3: Non-Maximum Suppression applied to RESULT 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
