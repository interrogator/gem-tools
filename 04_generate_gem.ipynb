{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    To do:\n",
    "    - Use pickle to store the training data.\n",
    "    - Pass text blocks to Tesseract.\n",
    "    - Pass photographs to NeuralTalk2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GeM annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For computer vision\n",
    "import cv2\n",
    "import mahotas\n",
    "from imutils import paths\n",
    "\n",
    "# For machine learning\n",
    "from __future__ import print_function\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For logging\n",
    "import logging\n",
    "from logging import FileHandler\n",
    "from vlogging import VisualRecord\n",
    "\n",
    "# For connected-component analysis\n",
    "from skimage.filters import threshold_adaptive\n",
    "from skimage import measure\n",
    "\n",
    "# For connected-component analysis\n",
    "import numpy as np\n",
    "\n",
    "# For encoding files\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the logging file and set the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"detect_elements\")\n",
    "fh = FileHandler(\"detect_and_classify_elements_log.html\", mode = \"w\")\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# Prevent logger output in IPython\n",
    "logger.propagate = False\n",
    "\n",
    "# Define a function to handle visual logging\n",
    "def vlog(image, title):\n",
    "    logger.debug(VisualRecord(title, image, fmt = \"png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def describe(image):\n",
    "    (means, stds) = cv2.meanStdDev(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))\n",
    "    colorStats = np.concatenate([means, stds]).flatten()\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis = 0)\n",
    "    \n",
    "    return np.hstack([colorStats, haralick])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imagePaths = sorted(paths.list_images('training_data/'))\n",
    "labels = []\n",
    "data = []\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath[imagePath.rfind('/') + 1:].split('_')[0]\n",
    "    image = cv2.imread(imagePath)\n",
    "    \n",
    "    features = describe(image)\n",
    "    labels.append(label)\n",
    "    data.append(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(data), np.array(labels), test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out a report on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(testData)\n",
    "print(classification_report(testLabels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare the document image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('test_images/2005-hwy-side_b-5.jpg')\n",
    "\n",
    "# Logging\n",
    "logger.debug(\"Image width: {}, height: {}\".format(image.shape[1], image.shape[0]))\n",
    "vlog(image, \"Original image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "vlog(gray, \"Grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply bilateral filtering to remove detail but preserve edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = (11, 41, 21)\n",
    "blurred = cv2.bilateralFilter(gray, params[0], params[1], params[2])\n",
    "\n",
    "# Logging\n",
    "logger.debug(\"Parameters for bilateral filtering: diameter of the pixel neighbourhood: {}, standard deviation for color: {}, standard deviation for space: {}\".format(params[0], params[1], params[2]))\n",
    "vlog(blurred, \"Bilaterally filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a kernel size for morphological operations.\n",
    "\n",
    "> The kernel size must be determined after deciding input image resolution. It should be based on type size and correspond roughly to the x-height of the font face used for body text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernelsize = (11, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Otsu's thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(T, thresholded) = cv2.threshold(blurred, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "# Logging\n",
    "logger.debug(\"Otsu's threshold: {}\".format(T))\n",
    "vlog(thresholded, \"Thresholded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform morphological operations on the document image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernelsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphological gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(thresholded.copy(), cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "# Logging\n",
    "logger.debug(\"Kernel size: {}\".format(kernelsize))\n",
    "vlog(gradient, \"Morphological gradient applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eroded = cv2.erode(gradient, None, iterations = 2)\n",
    "\n",
    "# Logging\n",
    "vlog(eroded, \"Morphological gradient eroded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform connected-components labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform connected component labeling and set up a mask for the labels to be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = measure.label(eroded, neighbors = 8, background = 0)\n",
    "\n",
    "gradient_mask = np.zeros(gradient.shape, dtype = \"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the labels twice:\n",
    "    1. Calculate the average number of pixels per label.\n",
    "    2. Decide which labels to include in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First loop\n",
    "\n",
    "numpixels_all = []\n",
    "\n",
    "for (i, label) in enumerate(np.unique(labels)):\n",
    "    if label == -1:\n",
    "        continue\n",
    "    labelmask = np.zeros(gradient.shape, dtype = \"uint8\")\n",
    "    labelmask[labels == label] = 255\n",
    "    numpixels = cv2.countNonZero(labelmask)\n",
    "    numpixels_all.append(numpixels)\n",
    "\n",
    "average = sum(numpixels_all) / len(numpixels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second loop\n",
    "\n",
    "for (i, label) in enumerate(np.unique(labels)):\n",
    "    if label == -1:\n",
    "        continue\n",
    "    labelmask = np.zeros(gradient.shape, dtype = \"uint8\")\n",
    "    labelmask[labels == label] = 255\n",
    "    numpixels = cv2.countNonZero(labelmask)\n",
    "    \n",
    "    if numpixels > (int(average) * 0.05):\n",
    "        gradient_mask = cv2.add(gradient_mask, labelmask)\n",
    "        \n",
    "# Logging\n",
    "logger.debug(\"Average size for label: {}\".format(average))   \n",
    "vlog(gradient_mask, \"Mask for morphological gradient after connected-components labeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Find and classify contours in the processed image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find contours in the image after applying morphological gradient and performing connected-components labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(contours, hierarchy) = cv2.findContours(gradient_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up another mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contour_mask = np.zeros(gradient_mask.shape, dtype = \"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw contours on the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in contours:\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    cv2.rectangle(contour_mask, (x, y), (x + w, y + h), (255, 255, 255), -1)\n",
    "\n",
    "# Logging\n",
    "vlog(contour_mask, \"Contour mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect and classify contours in the mask and draw them on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(maskcontours, maskhierarchy) = cv2.findContours(contour_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmlfile = codecs.open('layout-1.xml', 'w', 'utf-8')\n",
    "\n",
    "preamble = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write preamble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmlfile.write(preamble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original = image.copy()\n",
    "\n",
    "oh = original.shape[0]\n",
    "ow = original.shape[1]\n",
    "\n",
    "segmentation = []\n",
    "area_model = []\n",
    "realization = []\n",
    "\n",
    "for num, mc in enumerate(maskcontours):\n",
    "    (x, y, w, h) = cv2.boundingRect(mc)\n",
    "    if h <= (0.9 * oh):\n",
    "        bounding_box = original[y:y+h, x:x+w]\n",
    "        features = describe(bounding_box)\n",
    "        prediction = model.predict(features)[0]\n",
    "        if prediction == 'text':\n",
    "            # Draw rectange on original image\n",
    "            cv2.rectangle(original, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "            # Describe layout unit\n",
    "            textual_layout_unit = '\\t\\t<layout-unit id=\"lay-1.' + str(num + 1) + '\"/>\\n'\n",
    "            # Describe sub-area\n",
    "            textual_sub_area = '\\t\\t<sub-area id=\"sa-1.' + str(num + 1) + '\" ' + 'startx=\"' + str(x) + '\" ' + 'starty=\"' + str(y) + '\" ' + 'endx=\"' + str(x + w) + '\" ' + 'endy=\"' + str(y + h) + '\"' + '/>\\n'\n",
    "            # Describe realization\n",
    "            textual_realization = '\\t\\t<realization xref=\"lay-1.' + str(num + 1) + '\" type=\"text\"/>\\n'\n",
    "            # Append descriptions to list\n",
    "            segmentation.append(textual_layout_unit)\n",
    "            area_model.append(textual_sub_area)\n",
    "            realization.append(textual_realization)\n",
    "        if prediction == 'photo':\n",
    "            # Draw rectange on original image\n",
    "            cv2.rectangle(original, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "            # Describe layout unit\n",
    "            visual_layout_unit = '\\t\\t<layout-unit id=\"lay-1.' + str(num + 1) + '\" alt=\"Photo\"/>\\n'\n",
    "            # Describe sub-area\n",
    "            visual_sub_area = '\\t\\t<sub-area id=\"sa-1.' + str(num + 1) + '\" ' + 'startx=\"' + str(x) + '\" ' + 'starty=\"' + str(y) + '\" ' + 'endx=\"' + str(x + w) + '\" ' + 'endy=\"' + str(y + h) + '\"' + '/>\\n'  \n",
    "            # Describe realization\n",
    "            visual_realization = '\\t\\t<realization xref=\"lay-1.' + str(num + 1) + '\" type=\"photo\" width=\"' + str(w) + 'px\" height=\"' + str(h) + 'px\"/>\\n'\n",
    "            # Append descriptions to list\n",
    "            segmentation.append(visual_layout_unit)\n",
    "            area_model.append(visual_sub_area)\n",
    "            realization.append(visual_realization)\n",
    "            \n",
    "vlog(original, \"RESULT 1: Contours detected in the contour mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate the GeM XML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate annotation for layout layer segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmentation_preamble = '\\t<segmentation>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(segmentation_preamble))\n",
    "\n",
    "for s in segmentation:\n",
    "    xmlfile.write(\"\".join(s))\n",
    "    \n",
    "segmentation_terminate = '\\t</segmentation>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(segmentation_terminate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate annotation for area model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "areamodel_preamble = '\\t<area-model>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(areamodel_preamble))\n",
    "\n",
    "for a in area_model:\n",
    "    xmlfile.write(\"\".join(a))\n",
    "    \n",
    "areamodel_terminate = '\\t</area-model>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(areamodel_terminate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate annotation for realization information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realization_preamble = '\\t<realization>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(realization_preamble))\n",
    "\n",
    "for r in realization:\n",
    "    xmlfile.write(\"\".join(r))\n",
    "    \n",
    "realization_terminate = '\\t</realization>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(realization_terminate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmlfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
