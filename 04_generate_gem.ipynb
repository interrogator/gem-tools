{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GeM annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computer vision\n",
    "import cv2\n",
    "import mahotas\n",
    "import numpy as np\n",
    "\n",
    "import imutils\n",
    "\n",
    "# Optical character recognition\n",
    "import pytesser\n",
    "\n",
    "# Machine learning\n",
    "from __future__ import print_function\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "import warnings\n",
    "from logging import FileHandler\n",
    "from vlogging import VisualRecord\n",
    "\n",
    "# Connected-component analysis\n",
    "from skimage.filters import threshold_adaptive\n",
    "from skimage import measure\n",
    "\n",
    "# File handling\n",
    "import codecs\n",
    "import pickle\n",
    "\n",
    "# GeM generator\n",
    "from generator import describe, detect_roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-trained data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datafile = \"data.db\"\n",
    "td_file = open(datafile, 'r')\n",
    "data = pickle.load(td_file)\n",
    "\n",
    "labelfile = \"labels.db\"\n",
    "ld_file = open(labelfile, 'r')\n",
    "labels = pickle.load(ld_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(data), np.array(labels), test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare the document image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(maskcontours, maskhierarchy) = detect_roi(\"test_images/2005-hwy-side_b-5.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layout_file_name = str(filename) + '-layout-1.xml'\n",
    "xmlfile = codecs.open(layout_file_name, 'w', 'utf-8')\n",
    "\n",
    "preamble = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write preamble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmlfile.write(preamble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original = image.copy()\n",
    "\n",
    "oh = original.shape[0]\n",
    "ow = original.shape[1]\n",
    "\n",
    "segmentation = []\n",
    "area_model = []\n",
    "realization = []\n",
    "\n",
    "for num, mc in enumerate(maskcontours):\n",
    "    (x, y, w, h) = cv2.boundingRect(mc)\n",
    "    if h <= (0.9 * oh):\n",
    "        bounding_box = original[y:y+h, x:x+w]\n",
    "        features = describe(bounding_box)\n",
    "        prediction = model.predict(features)[0]\n",
    "        if prediction == 'text':\n",
    "            # Draw rectange on original image\n",
    "            cv2.rectangle(original, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "            # Describe layout unit\n",
    "            textual_layout_unit = '\\t\\t<layout-unit id=\"lay-1.' + str(num + 1) + '\"/>\\n'\n",
    "            # Describe sub-area\n",
    "            textual_sub_area = '\\t\\t<sub-area id=\"sa-1.' + str(num + 1) + '\" ' + 'startx=\"' + str(x) + '\" ' + 'starty=\"' + str(y) + '\" ' + 'endx=\"' + str(x + w) + '\" ' + 'endy=\"' + str(y + h) + '\"' + '/>\\n'\n",
    "            # Describe realization\n",
    "            textual_realization = '\\t\\t<realization xref=\"lay-1.' + str(num + 1) + '\" type=\"text\"/>\\n'\n",
    "            # Append descriptions to list\n",
    "            segmentation.append(textual_layout_unit)\n",
    "            area_model.append(textual_sub_area)\n",
    "            realization.append(textual_realization)\n",
    "        if prediction == 'photo':\n",
    "            # Draw rectange on original image\n",
    "            cv2.rectangle(original, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "            # Describe layout unit\n",
    "            visual_layout_unit = '\\t\\t<layout-unit id=\"lay-1.' + str(num + 1) + '\" alt=\"Photo\"/>\\n'\n",
    "            # Describe sub-area\n",
    "            visual_sub_area = '\\t\\t<sub-area id=\"sa-1.' + str(num + 1) + '\" ' + 'startx=\"' + str(x) + '\" ' + 'starty=\"' + str(y) + '\" ' + 'endx=\"' + str(x + w) + '\" ' + 'endy=\"' + str(y + h) + '\"' + '/>\\n'  \n",
    "            # Describe realization\n",
    "            visual_realization = '\\t\\t<realization xref=\"lay-1.' + str(num + 1) + '\" type=\"photo\" width=\"' + str(w) + 'px\" height=\"' + str(h) + 'px\"/>\\n'\n",
    "            # Append descriptions to list\n",
    "            segmentation.append(visual_layout_unit)\n",
    "            area_model.append(visual_sub_area)\n",
    "            realization.append(visual_realization)\n",
    "            \n",
    "vlog(original, \"RESULT 1: Contours detected in the contour mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate the GeM XML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate annotation for layout layer segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmentation_preamble = '\\t<segmentation>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(segmentation_preamble))\n",
    "\n",
    "for s in segmentation:\n",
    "    xmlfile.write(\"\".join(s))\n",
    "    \n",
    "segmentation_terminate = '\\t</segmentation>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(segmentation_terminate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate annotation for area model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "areamodel_preamble = '\\t<area-model>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(areamodel_preamble))\n",
    "\n",
    "for a in area_model:\n",
    "    xmlfile.write(\"\".join(a))\n",
    "    \n",
    "areamodel_terminate = '\\t</area-model>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(areamodel_terminate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate annotation for realization information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realization_preamble = '\\t<realization>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(realization_preamble))\n",
    "\n",
    "for r in realization:\n",
    "    xmlfile.write(\"\".join(r))\n",
    "    \n",
    "realization_terminate = '\\t</realization>\\n'\n",
    "\n",
    "xmlfile.write(\"\".join(realization_terminate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmlfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
