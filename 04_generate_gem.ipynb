{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GeM annotation\n",
    "\n",
    "This Jupyter notebook can be used to generate XML annotation for describing the content and layout of multimodal documents, according to the schema defined by the Genre and Multimodality (GeM) model (Bateman 2008). The goal of this notebook is to facilitate the process of describing the layout, which has been previously identified as a major bottleneck for annotating documents using the GeM model (Thomas 2009; Hiippala 2015).\n",
    "\n",
    "It should be noted that this notebook does not generate traditional human-annotated GeM markup, but rather a machine-readable variant, which may be referred to as *autogem*. However, various tools will be provided as a part of the <a href=\"https://github.com/thiippal/gem-tools\">gem-tools</a> repository for visualizing *autogem* annotation.\n",
    "\n",
    "The notebook is intended to be friendy to novice users: therefore most of the functions reside in an external file named generator.py. More advanced users may examine this file for a better understanding of the notebook's operation. \n",
    "\n",
    "** References **\n",
    "\n",
    "Bateman, J.A. (2008) *Multimodality and Genre: A Foundation for the Systematic Analysis of Multimodal Documents*. London: Palgrave.\n",
    "\n",
    "Hiippala, T. (2015) *The Structure of Multimodal Documents: An Empirical Approach*. New York and London: Routledge.\n",
    "\n",
    "Thomas, M. (2009) *Localizing pack messages: A framework for corpus-based cross-cultural\n",
    "multimodal analysis*. PhD thesis, University of Leeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computer vision\n",
    "import cv2\n",
    "\n",
    "# File handling\n",
    "import codecs\n",
    "\n",
    "# GeM generator\n",
    "from generator import classify, describe, detect_roi, extract_bu, false_positives, generate_photo, generate_text, load_model, preprocess, project, sort_contours\n",
    "\n",
    "# Jupyter notebook\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pre-trained data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process the document image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the document image.\n",
    "\n",
    "For best results, use documents with a resolution of 300 DPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image, original, filename, filepath = preprocess(\"test_images/2005-hwy-side_b-5.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect regions of interest in the document image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a kernel for morphological operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = (11, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect regions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contours = detect_roi(image, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort the detected contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_contours = sort_contours(contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify the detected contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classified_contours, contour_types = classify(sorted_contours, image, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw the detected contours for examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(filename=\"output/image_contours.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mark false positives and erroneous or missing elements.\n",
    "\n",
    "Check the image above for any false positives. Enter their numbers, separated by a space, below (e.g. 11 24 32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp_list = false_positives(raw_input())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you wish to mark additional elements in the document image (y/n)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that takes a raw input: 'y' opens a new window for marking the areas, 'n' continues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project the contours on the original high resolution document image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hires_contours = project(image, original, classified_contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate the annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the XML file for the layout layer annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layout_file_name = 'output/' + str(filename) + '-layout-2.xml'\n",
    "layout_xml = codecs.open(layout_file_name, 'w', 'utf-8')\n",
    "\n",
    "layout_xml_opening = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n\\n <gemLayout>\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the XML file for the base layer annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_file_name = 'output/' + str(filename) + '-base-2.xml'\n",
    "base_xml = codecs.open(base_file_name, 'w', 'utf-8')\n",
    "\n",
    "base_xml_opening = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n\\n <gemBase>\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin the generating the annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layout_xml.write(layout_xml_opening)\n",
    "base_xml.write(base_xml_opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up lists and dictionaries for the annotation\n",
    "\n",
    "# Base layer\n",
    "base_units = []\n",
    "base_layout_mapping = {}\n",
    "\n",
    "# Layout layer\n",
    "segmentation = []\n",
    "area_model = []\n",
    "realization = []\n",
    "\n",
    "# Loop over the regions of interest\n",
    "for num, hc in enumerate(hires_contours):\n",
    "    # Check if the region of interest is flagged as a false positive\n",
    "    if num in fp_list:\n",
    "        continue\n",
    "    else:\n",
    "        # Define the region of interest in the high resolution image\n",
    "        (x, y, w, h) = cv2.boundingRect(hc)\n",
    "        bounding_box = original[y:y+h, x:x+w]\n",
    "        \n",
    "        # Check the classification\n",
    "        if contour_types[num] == 'text':\n",
    "            \n",
    "            # Extract base units\n",
    "            layout_unit_id, b_units = extract_bu(original, x, w, y, h, num)\n",
    "            \n",
    "            # Loop over the base units\n",
    "            for base_unit in b_units:\n",
    "                # Add base units to the list\n",
    "                base_units.append(base_unit)\n",
    "                # Assign identifier to each base unit\n",
    "                base_id = 'u-1.' + str(len(base_units))\n",
    "                # Map the base units to their layout unit\n",
    "                base_layout_mapping[base_id] = layout_unit_id\n",
    "                # Generate XML annotation\n",
    "                unit = '\\t<unit id=\"' + base_id + '\">' + base_unit.replace('\\n', ' ').rstrip() + '</unit>\\n'\n",
    "                # Write the XML into the base layer file\n",
    "                base_xml.write(\"\".join(unit))\n",
    "            \n",
    "            # Generate XML entries for the layout layer\n",
    "            lu, sa, re = generate_text(original, x, w, y, h, num, base_layout_mapping)\n",
    "            # Append the XML entries to the corresponding lists\n",
    "            segmentation.append(lu)\n",
    "            area_model.append(sa)\n",
    "            realization.append(re)\n",
    "            \n",
    "        if contour_types[num] == 'photo':\n",
    "            \n",
    "            # Set up a placeholder for manual description\n",
    "            base_units.append(str('Photo'))\n",
    "            # Assign an identifier to the base unit\n",
    "            vbase_id = 'u-1.' + str(len(base_units))\n",
    "            # Map the base unit to the layout unit\n",
    "            base_layout_mapping[vbase_id] = num\n",
    "            # Generate XML annotation\n",
    "            vunit = '\\t<unit id=\"' + vbase_id + '\" alt=\"Photo\"/>\\n'\n",
    "            # Write the XML into the base layer file\n",
    "            base_xml.write(\"\".join(vunit))\n",
    "\n",
    "            # Generate XML entries for the layout layer\n",
    "            vlu, vsa, vre = generate_photo(original, x, w, y, h, num, base_layout_mapping)\n",
    "            \n",
    "            # Append descriptions to list\n",
    "            segmentation.append(vlu)\n",
    "            area_model.append(vsa)\n",
    "            realization.append(vre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate the GeM XML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate annotation for layout layer segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segmentation_opening = '\\t<segmentation>\\n'\n",
    "\n",
    "layout_xml.write(\"\".join(segmentation_opening))\n",
    "\n",
    "for s in segmentation:\n",
    "    layout_xml.write(\"\".join(s))\n",
    "    \n",
    "segmentation_closing = '\\t</segmentation>\\n'\n",
    "\n",
    "layout_xml.write(\"\".join(segmentation_closing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate annotation for area model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "areamodel_opening = '\\t<area-model>\\n'\n",
    "\n",
    "layout_xml.write(\"\".join(areamodel_opening))\n",
    "\n",
    "for a in area_model:\n",
    "    layout_xml.write(\"\".join(a))\n",
    "    \n",
    "areamodel_closing = '\\t</area-model>\\n'\n",
    "\n",
    "layout_xml.write(\"\".join(areamodel_closing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate annotation for realization information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realization_opening = '\\t<realization>\\n'\n",
    "\n",
    "layout_xml.write(\"\".join(realization_opening))\n",
    "\n",
    "for r in realization:\n",
    "    layout_xml.write(\"\".join(r))\n",
    "    \n",
    "realization_closing = '\\t</realization>\\n'\n",
    "\n",
    "layout_xml.write(\"\".join(realization_closing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the closing tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layout_xml_closing = '</gemLayout>'\n",
    "base_xml_closing = '</gemBase>'\n",
    "\n",
    "layout_xml.write(\"\".join(layout_xml_closing))\n",
    "base_xml.write(\"\".join(base_xml_closing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layout_xml.close()\n",
    "base_xml.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
